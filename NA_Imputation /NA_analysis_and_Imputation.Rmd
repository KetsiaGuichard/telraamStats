
# Importation des packages
```{r}

# remove.packages("telraamStats")
# 
# 
# devtools::install_github("https://github.com/KetsiaGuichard/telraamStats",
#                               dependencies = TRUE, 
#                               build_vignettes = TRUE,
#                               force = TRUE)


pacman::p_load(tidyverse,telraamStats,lubridate,forecast,prophet)

```

# Importations des besoins de l'environments
```{r}
usethis::edit_r_environ()

Sys.getenv("token")
```


#Importation des fonctions 
```{r}
source("Clean_Data.R")
source("Imputation_function.R")
source("Utilities_functions.R")
```


# Importation et nettoyage des données
```{r}
load("/Users/paulvallee/Desktop/Stage CREM/Code R/data/segments_2ans.RData")
data_04$segment_name <- "RueDesEcoles-14"

segments <- list(data_01,data_02,data_04,data_05,data_06,data_07,data_08,data_10,data_11,data_13,data_14,data_15,data_16,data_18)


#Suppression manuel des periodes d'inactivités des capteurs non reperable 
data_15 <- delete_segment(data_15,"RueManoirs-15","2023-10-01","2024-01-01")



segments_clear <- Clean_NA_segments(segments, 85,24)
liste_segment <- Clean_NA_segments_list(segments, 85,24)

segments_clear$segment_name <- as.factor(as.character(segments_clear$segment_name))
segments_clear$weekday <- as.factor(as.character(segments_clear$weekday))
segments_clear$vacation <- as.character(segments_clear$vacation)
segments_clear$date <- as.Date(segments_clear$date)
```

# Importation des données météo 
```{r}
meteo <- read.csv("/Users/paulvallee/Desktop/Stage CREM/Code R/data/meto_St_jac_05_2023_2024.csv", sep = ";")
meteo <- meteo %>% select(DATE,`T`,UV,DIR2,INS,VV,UX,RR1,DRR1)
meteo$DATE <- ymd_h(meteo$DATE)
meteo$DATE <- with_tz(meteo$DATE, tzone =)
```

# Data relatif au capteur V2
```{r message=FALSE, warning=FALSE}
dataV2 <- read.csv("/Users/paulvallee/Desktop/Stage CREM/Code R/data/20230518_20240517_v2_sensors_extract.csv")
dataV2$uptime_quality <- ifelse(dataV2$uptime >=0.5 ,TRUE,FALSE)
clean_dataV2 <- Clean_NA_segments(dataV2)
```


#Enrichissement des données 

## Version des capteurs 
```{r}
V2 <- c("Burel-01","ParisArcEnCiel-05","RueGdDomaine-07", "RuePrieure-11")
V1 <- c("Leclerc-02","rueVignes-04", "RteVitre-06", "StDidierSud-10","RueVeronniere-13", "RueDesEcoles-14", "RueManoirs-15", "RueToursCarree-16", "BoulevardLiberté-18")
KO <- c("ParisMarche-03","StDidierNord-08","RueGdDomaine-09","RueVallee","RueCottage-12","PlaceHotelDeVille-17")

segments_clear$version <- ifelse(segments_clear$segment_name %in% V2, "V2", ifelse(segments_clear$segment_name %in% V1, "V1", ifelse(segments_clear$segment_name %in% KO, "KO", NA)))
```

## Données météo
```{r}
segments_clear <- segments_clear %>% left_join(meteo, by = c("date" = "DATE"))
```

## Type de données manquante 

```{r}
segments_clear <- NA_Type(segments_clear)
```



# Analyse des données 

```{r}
plot_NA(segments_clear)
```


```{r}

t <- segments_clear %>%  filter(segment_name == "RueToursCarree-16") 
plot.ts(t$uptime)

ggtsdisplay(as.numeric(t$uptime),main = "Saisonnalité des valeurs manquantes pour le capteur RueToursCarree-16")

#lag de 10
ggtsdisplay(as.numeric(diff(t$uptime, lag = 10,differences = 1)
),main = "Saisonnalité des valeurs manquantes pour le capteur RueToursCarree-16")

```

```{r}
#Comparer la tendance de VV avec uptime
t <- segments_clear %>%  filter(segment_name == "RueToursCarree-16")
plot.ts(t$VV)
plot.ts(t$uptime)
```



## Corrélation

```{r}
segment_cor <- segments_clear %>% mutate(segment_name = as.factor(as.character(segment_name)),heavy = as.numeric(heavy),car = as.numeric(car)) %>%  select(date,segment_name,heavy,car) %>% mutate(vehicle = as.numeric(heavy + car)) %>% select(-heavy,-car) %>% pivot_wider(names_from = segment_name,values_from = vehicle) 


#d <- segment_cor %>% select(-date) %>% na.omit(d) %>% cor() %>% corrplot::corrplot( method = "number", type = "upper", tl.col = "black", tl.srt = 45)


```




# Imputation des données 


# Méthode 1 : Clustering par proximité géographique en tenant compte du sens des routes : ECHEC

```{r}
library(igraph)

# Créer un dataframe avec les relations entre les segments
relations <- data.frame(
  segment_name = c("Burel-01", "Leclerc-02", "rueVignes-04", "ParisArcEnCiel-05", "RteVitre-06", "RueGdDomaine-07", "StDidierSud-10", "RuePrieure-11", "RueDesEcoles-14", "RueManoirs-15", "RueVeronniere-13", "RueToursCarree-16", "PlaceHotelDeVille-17", "BoulevardLiberte-18", "BoulevardLaennecSud", "BoulevardLaennecNord"),
  destination = c("BoulevardLaennecNord", "RueManoirs-15", "RuePrieure-11", "ParisMarche-03", "RueGdDomaine-07", "RteVitre-06", "RueDesEcoles-14", "rueVignes-04", "StDidierSud-10", "ParisArcEnCiel-05", "ParisArcEnCiel-05", "RuePrieure-11", "RuePrieure-11", "BoulevardLaennecSud", "BoulevardLaennecNord", "BoulevardLaennecSud")
)

# Convertir segment_name et destination en facteur
relations$segment_name <- as.factor(relations$segment_name)
relations$destination <- as.factor(relations$destination)

# Créer le graphe à partir du dataframe
graph <- graph_from_data_frame(relations, directed = TRUE)

# Afficher le graphe
plot(graph, layout = layout.auto)


#Création de la matrice d'adjacence
adjacency_matrix <- as_adjacency_matrix(graph, attr = NULL, edges = FALSE, names = TRUE, sparse = FALSE)
adjacency_matrix
```

```{r}
set.seed(123)
#Recuperer la sous matrice correspondant au colonne de test
adjacency_matrix_sub <- adjacency_matrix[1:9,1:9]
colnames(adjacency_matrix_sub)

temoin <- segments_clear %>% filter(uptime > 0.5) %>% select(date,segment_name,heavy,car) %>% mutate(vehicle = heavy + car) %>% select(-heavy,-car) %>% pivot_wider(names_from = segment_name,values_from = vehicle)  %>% na.omit()

#Crée des valeurs manquantes aléatoire dans le jeu de données
test2 <- temoin
# Nombre de valeurs manquantes à créer
num_missing <- 50

vec_x <- c()
vec_y <- c()

for(i in 1:num_missing){
  # Choisir un élément aléatoire dans le jeu de données
  x <- sample(1:nrow(test), 1)
  y <- sample(2:ncol(test), 1)
  vec_x <- c(vec_x,x)
  vec_y <- c(vec_y,y)
  # Remplacer la valeur correspondante par NA
  test2[x,y] <- NA
}

test2
```

```{r}
# Reconstruire test2 en utilisant les valeurs des capteurs voisins
for (j in 2:ncol(test2)){
  for (i in 1:nrow(test2)){
    if(is.na(test2[i,j])){
      # Recuperer nom colonne
      col_name <- colnames(test2)[j]
      # Recuperer les noms des colonnes voisines
      neighbors <- colnames(adjacency_matrix_sub)[which(adjacency_matrix_sub[col_name,] == 1)]
      
      #Si il existe un voisin et que sa valeur est non manquante alors remplacé par cette valeurs 
      if(length(neighbors) == 1 ){
            if(!is.na(test2[i,neighbors])){
              test2[i,j] <- test2[i,neighbors]
            }
      }
      else if(length(neighbors) > 1){
        #Si il existe plusieurs voisins alors on prend la moyenne
        test2[i,j] <- mean(test2[i,neighbors],na.rm = TRUE)
        
      }
      else if(length(neighbors) == 0){
        #Si il n'existe pas de voisin alors on prend la moyenne de la colonne
        test2[i,j] <- NA}
    }
  }
}
      
is.na(test2) %>% sum()


mean_error <- 0
#Comparer les valeurs imputé avec les valeurs réels
for(i in 1:length(vec_x)){
    print(paste("Valeur réel : ",test[vec_x[i],vec_y[i]]," Valeur imputé : ",test2[vec_x[i],vec_y[i]]))
  }

```



# Méthode 2 : Imputation par serie temporelle

#Test sur un segment 
```{r}
Leclerc2 <- segments_clear %>% filter(segment_name == "Leclerc-02")
obj_input <- TimeSeries_Imputation(Leclerc2)
obj_input$components
obj_input$fitting_curve
obj_input$Imputation
```

```{r}
ParisArcEnCiel <- segments_clear %>% filter(segment_name == "ParisArcEnCiel-05")
obj_input <- TimeSeries_Imputation(ParisArcEnCiel)
obj_input$components
obj_input$fitting_curve
obj_input$Imputation
```

```{r}
#Modify ParisArcEnCIel to having create  time serie model based only on the time and weekday
ParisArc2 <- ParisArcEnCiel %>% select(hour,weekday,car,heavy) %>% mutate(vehicle = car + heavy) %>% group_by(weekday,hour) %>% summarise(vehicle = mean(vehicle)) %>% ungroup()
ParisArc2 %>% ggplot(aes(x = hour,y = vehicle)) + geom_line() + facet_wrap(~weekday)



obj_input <- TimeSeries_Imputation(ParisArc2)
obj_input$components
obj_input$fitting_curve
obj_input$Imputation

```


# Test sur tout les segments 
```{r}
liste_pred <- TimeSeries_Imputation_list(liste_segments)

```



#Résultat de l'imputation 
```{r}
for(i in 1:length(liste_pred)){
  print(liste_pred[[i]]$fitting_curve)
  print(liste_pred[[i]]$Imputation)
}
```


our mesurer la qualité d'un modèle temporel, vous pouvez utiliser plusieurs tests statistiques, en fonction de vos besoins et du type de modèle que vous avez utilisé. Voici quelques options courantes :

Erreur moyenne absolue (MAE) : Mesure la moyenne des écarts absolus entre les valeurs prédites et les valeurs réelles. Plus la MAE est faible, meilleure est la performance du modèle.

Erreur quadratique moyenne (MSE) : Calcule la moyenne des carrés des écarts entre les valeurs prédites et les valeurs réelles. Comme pour la MAE, une valeur plus faible indique une meilleure performance, mais elle donne plus de poids aux grandes erreurs.

Erreur quadratique moyenne racine (RMSE) : C'est la racine carrée de la MSE. Comme la MSE, mais exprimée dans les mêmes unités que la variable cible, ce qui la rend plus interprétable.

Erreur absolue moyenne en pourcentage (MAPE) : Calcule la moyenne des écarts absolus en pourcentage entre les valeurs prédites et les valeurs réelles. Utile pour évaluer la précision relative du modèle.

Coefficient de détermination (R²) : Indique la proportion de la variance de la variable dépendante qui est prévisible à partir de la variable indépendante. Une valeur proche de 1 indique un bon ajustement du modèle.

Test de Ljung-Box : Test de l'autocorrélation des résidus d'un modèle ARIMA. Il évalue si les résidus sont indépendants les uns des autres.

Test de Durbin-Watson : Utilisé pour tester l'autocorrélation des résidus dans un modèle de régression. Il teste si les résidus présentent une corrélation linéaire les uns avec les autres.

Critère d'information d'Akaike (AIC) et Critère d'information bayésien (BIC) : Mesurent la qualité d'ajustement d'un modèle tout en pénalisant la complexité. Des valeurs plus basses indiquent un meilleur ajustement du modèle.

```{r}
library(forecast)

data <- liste_segment[[1]]$data
data$vehicle <- data$heavy + data$car
ets_model <- ets(data$vehicle, model = "ZZZ")
ets_model

#Prédiction
forecast_ets <- forecast(ets_model, h = 10)
forecast_ets
plot(forecast_ets)



```



# Construction d'une Pipeline de test


On choisit un segment qui parrait interessant sans trop de defauts. 
```{r}
segment <- as.vector(unique(dataV2$segment_fullname))
segment <- segment[1:7]
for(i in 1:length(segment)){
  data <- dataV2 %>% filter(segment_fullname == segment[i])
  data$vehicle <- data$heavy + data$car
  data$datetime <- as.POSIXct(data$date)
  print(ggplot(data,aes(x = datetime,y = vehicle)) + geom_point() + ggtitle(segment[i]))
}


```
On peut essayer celui Rue de Prieuré

```{r}
Prieur <- dataV2 %>% filter(segment_fullname == "9000005665 - Rue du Prieuré - autre") 
Prieur %>% mutate(date = as.POSIXct(date)) %>%  summary()

#Transform public_holiday to binary and rename it
 Prieur <- Prieur %>% mutate(public_holiday = ifelse(public_holiday == 1,TRUE,FALSE)) %>% rename(holiday = public_holiday) 
```



```{r}
TimeSeries_Imputation <- function(data) {
  # Load the prophet library
  library(prophet)
  
  # Prepare the training set by creating 'ds' and 'y' columns
  train_set <- data %>% mutate(ds = date, y = ifelse(uptime_quality, car + heavy, NA)) %>% select(ds, y)
  # Prepare the test set by filtering out rows where uptime_quality is false
  test_set <- data %>% filter(!uptime_quality) %>% mutate(ds = date) %>% select(ds)
  
  # Prepare the holidays data for the Prophet model
  holidays <- data %>% filter(holiday) %>% mutate(lower_window = 0, upper_window = 1, vacation = as.character(vacation)) %>% 
    select(vacation, date, lower_window, upper_window) %>% rename(holiday = vacation, ds = date)
  
  # Train the Prophet model using the training set and holidays
  model <- prophet(train_set, holidays = holidays,seasonality.prior.scale= 0.5)
  # Predict values using the test set
  pred <- predict(model, test_set)
  
  # Adjust predictions on the training set to obtain the fitting curve
  ajust <- predict(model, train_set)
  fitting_curve <- plot(model, ajust)
  
  # Plot the components of the model
  components <- prophet_plot_components(model, pred)
  
  # Prepare the prediction data for plotting
  dpred <- pred %>% select(ds, yhat) %>% rename(y = yhat) %>% mutate(type = "pred", y = ifelse(y < 0, 0, y))
  # Prepare the real data for plotting
  dtrain <- train_set %>% na.omit() %>% select(ds, y) %>% mutate(type = "real")
  
  # Convert 'ds' columns to POSIXct format for both data frames
  dtrain$ds <- as.POSIXct(dtrain$ds)
  dpred$ds <- as.POSIXct(dpred$ds)
  
  # Create a ggplot of the input data, including both real and predicted values
  plot_inputdata <- ggplot() +
    geom_point(data = dtrain, aes(x = ds, y = y, color = type)) +
    geom_point(data = dpred, aes(x = ds, y = y, color = type)) +
    ggtitle(paste("Prédiction de la fréquentation du segment", data$segment_name[1])) +
    xlab("Date") +
    ylab("Nombre de véhicules") +
    theme(legend.position = "none")
  
  # Return a list containing the prediction, fitting curve, components, and plot
  return(list(prediction = dpred, fitting_curve = fitting_curve, components = components, Imputation = plot_inputdata))
}
TimeSeries_Imputation <- function(data) {
  # Load the prophet library
  library(prophet)
  
  # Prepare the training set by creating 'ds' and 'y' columns
  train_set <- data %>% mutate(ds = date, y = ifelse(uptime_quality, car + heavy, NA)) %>% select(ds, y)
  # Prepare the test set by filtering out rows where uptime_quality is false
  test_set <- data %>% filter(!uptime_quality) %>% mutate(ds = date) %>% select(ds)
  
  # Prepare the holidays data for the Prophet model
  holidays <- data %>% filter(holiday) %>% mutate(lower_window = 0, upper_window = 1, vacation = as.character(vacation)) %>% 
    select(vacation, date, lower_window, upper_window) %>% rename(holiday = vacation, ds = date)
  
  # Train the Prophet model using the training set and holidays
  model <- prophet(train_set, holidays = holidays)
  # Predict values using the test set
  pred <- predict(model, test_set)
  
  # Adjust predictions on the training set to obtain the fitting curve
  ajust <- predict(model, train_set)
  fitting_curve <- plot(model, ajust)
  
  # Plot the components of the model
  components <- prophet_plot_components(model, pred)
  
  # Prepare the prediction data for plotting
  dpred <- pred %>% select(ds, yhat) %>% rename(y = yhat) %>% mutate(type = "pred", y = ifelse(y < 0, 0, y))
  # Prepare the real data for plotting
  dtrain <- train_set %>% na.omit() %>% select(ds, y) %>% mutate(type = "real")
  
  # Convert 'ds' columns to POSIXct format for both data frames
  dtrain$ds <- as.POSIXct(dtrain$ds)
  dpred$ds <- as.POSIXct(dpred$ds)
  
  # Create a ggplot of the input data, including both real and predicted values
  plot_inputdata <- ggplot() +
    geom_point(data = dtrain, aes(x = ds, y = y, color = type)) +
    geom_point(data = dpred, aes(x = ds, y = y, color = type)) +
    ggtitle(paste("Prédiction de la fréquentation du segment", data$segment_name[1])) +
    xlab("Date") +
    ylab("Nombre de véhicules") +
    theme(legend.position = "none")
  
  # Return a list containing the prediction, fitting curve, components, and plot
  return(list(prediction = dpred, fitting_curve = fitting_curve, components = components, Imputation = plot_inputdata))
}

```

```{r}

modelPrieur$fitting_curve 
```
```{r}
modelPrieur <- TimeSeries_Imputation(Prieur)
modelPrieur$fitting_curve 
```








